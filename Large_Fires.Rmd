---
title: "Hawaii Fire Revised Analysis"
author: "Annie Kellner"
date: "2025-04-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE
)
```

```{r load-libraries}

library(tidyverse)
library(kableExtra)
library(MuMIn)
library(pscl)
library(MASS)
library(fitdistrplus)
library(ggplot2)
library(poweRlaw)
library(glmmTMB)
library(AICcmodavg)
library(pROC)
library(caret)
library(MLmetrics)

```

```{r load-data}

pta_fire <- read_csv("./Data/PTA_East/PTA_East_FDRS_Wildfires.csv")
r17_fire <- read_csv("./Data/Range17/PTA_Off_Post_Fire_History.csv")
kma_fire <- read_csv("C:/Users/akellner/OneDrive - Colostate/Documents/Fire/Data/KMA_Wx_Fire_Data/KMA_FDRS_Wildfires.csv")

#r17acres <- read_csv("./Data/Range17/R17_Acreage.csv")

intensity <- read_csv("./Data/Multiple_Fires.csv")

```

```{r Dates}

pta_fire$Date <- as.Date(pta_fire$Date, format = "%m/%d/%Y")
r17_fire$Date <- as.Date(r17_fire$Date, format = "%m/%d/%Y")
kma_fire$Date <- as.Date(kma_fire$Date, format = "%m/%d/%Y")

```


## Fires >= 5 Acres & >= 2 acres


```{r create-df}

intensity <- data.frame(
    matrix(NA, 
           nrow = 7,  # Number of metrics you want to track
           ncol = 3,  # Number of locations
           dimnames = list(
               c("Days_w_Multiple_Fires",
                 "MaxFires_OneDay",
                 "Days_2Fires",
                 "Days_3Fires",
                 "Days_4Fires",
                 "Acres_5+",
                 "Acres_2+"),  # Row names
               c("KMA", "PTA", "Range17")  # Column names
           )
    )
)

```

```{r get-acreage-kma}

# Get fires >= 5 and >=2 acres

kma5fire <- kma_fire %>%
  filter(acres >= 5) #%>%
  #select(Date, acres) 

intensity["Acres_5+", "KMA"] <- tally(kma5fire)$n

kma2fire <- kma_fire %>%
  filter(acres >= 2) #%>%
  #select(Date, acres) 

intensity["Acres_2+", "KMA"] <- tally(kma2fire)$n

intensity["Days_w_Multiple_Fires", "KMA"] <- 29
intensity["MaxFires_OneDay", "KMA"] <- 3
intensity["Days_2Fires", "KMA"] <- 28
intensity["Days_3Fires", "KMA"] <- 1
intensity["Days_4Fires", "KMA"] <- 0

```


```{r get-acreage-pta}

pta5fire <- pta_fire %>%
  filter(acres >= 5) %>%
  arrange(Date)

intensity["Acres_5+", "PTA"] <- tally(pta5fire)$n

pta2fire <- pta_fire %>%
  filter(acres >= 2) %>%
  arrange(Date)

intensity["Acres_2+", "PTA"]<- tally(pta2fire)$n

intensity["Days_w_Multiple_Fires", "PTA"] <- 26
intensity["MaxFires_OneDay", "PTA"] <- 4
intensity["Days_2Fires", "PTA"] <- 18
intensity["Days_3Fires", "PTA"] <- 7
intensity["Days_4Fires", "PTA"] <- 1

```

```{r get-acreage-r17}


r17_5fire <- r17_fire %>%
  filter(ACRES_BURN >= 5) %>%
  arrange(Date)

intensity["Acres_5+", "Range17"] <- tally(r17_5fire)$n

r17_2fire <- r17_fire %>%
  filter(ACRES_BURN >= 2) %>%
  arrange(Date)

intensity["Acres_2+", "Range17"] <- tally(r17_2fire)$n


intensity["Days_w_Multiple_Fires", "Range17"] <- 20
intensity["MaxFires_OneDay", "Range17"] <- 4
intensity["Days_2Fires", "Range17"] <- 15
intensity["Days_3Fires", "Range17"] <- 4
intensity["Days_4Fires", "Range17"] <- 1


knitr::kable(intensity,
             caption = "Summary of Large and/or Multiple Fires") %>%
    kable_styling(bootstrap_options = c("striped", "hover"),
                full_width = FALSE) %>%
  row_spec(0:nrow(intensity),
           background = "white",
           color = "black")

```


## ADDING EXPLANATORY VARIABLES FROM PTA/R17 TO KMA MODELS

I added KBDI, Temp, and BI to the KMA models because those were the most important variables in PTA East and Range 17. 

# All Models with AICc < 2

```{r}

rm(list = ls()) # using dataframes with predictor and response variables

kma <- readRDS(file = "./Data/CompleteDFs/KMA_20250327.Rds")
ptaE <- readRDS(file = "./Data/CompleteDFs/ptaE_20250327.Rds")
r17 <- readRDS(file = "./Data/CompleteDFs/r17_20250327.Rds")

# Dredging

globMod <- glm(Presence ~ F100 + FM1 + KBDI + Temp + BI, data = kma, family = binomial)


options(na.action = "na.fail")

model_dredge <- dredge(globMod, 
                       evaluate = TRUE,
                       rank = "AICc")

# View top models

top_models_kma <- model.sel(model_dredge, rank = "AICc")
subset(top_models_kma, delta < 2)

```

# Model Averaging

```{r}

avg_model <- model.avg(model_dredge, subset = delta < 2)
summary(avg_model)


```

# Variable Importance

```{r}

imp <- sw(model_dredge)

var_importance_df <- data.frame(
  Variable = names(imp),
  Sum_of_Weights = imp
) %>%
  arrange(desc(Sum_of_Weights)) 

```

**FM1 is still the most predictive variable for KMA, followed by F100 (i.e., the results did not change upon adding important variables from other regions). Temp emerged in the top model set and showed a variable importance weight just below that of F100, but I'd hesitate to include it. The coefficients in the individual models as well as the model average are the inverse of what I'd expect. I added it because it was very important in the PTA first-pass results, but it wasn't originally included because the univariate analysis did not show a strong association.**

**I expected this result, but it was still worth a shot, and this exercise gave me a little boost of confidence in our variable selection process**


### PART TWO: THE HURDLE MODEL

I think this model might make sense for our data. It accounts for zero-inflation, but isn't exactly the same as a zero-inflated model. The following are reasons a person might choose a hurdle model (in general):

  * Zeros and Ones are generated by different processes
      We can discuss this, but I think it's a reasonable assumption for this analysis. Ignition would be what leads to Ones,         and a lack of ignition would lead to zeros, even under the same conditions otherwise.
      
  * This model allows for modeling presence/absence separately from intensity.
  
Hurdle Models separate the analysis into two parts:
  1. Logistic Regression that predicts whether or not a fire occurs, and
  2. A truncated model that predicts the size or intensity of the fire
  
  
```{r add-acreage-to-DFs}

# KMA

burnKMA <- kma_fire %>%
  group_by(Date) %>%
  mutate(Total_Acres_Burned = sum(acres)) %>%
  select(Date, Total_Acres_Burned)

kma <- kma %>%
  left_join(burnKMA) %>%
  replace_na(list(Total_Acres_Burned = 0))

# PTA East

burnPTA <- pta_fire %>%
  group_by(Date) %>%
  mutate(Total_Acres_Burned = sum(acres)) %>%
  select(Date, Total_Acres_Burned) 

  
ptaE <- ptaE %>%
  left_join(burnPTA) %>%
  replace_na(list(Total_Acres_Burned = 0))

# Range 17

burnR17 <- r17_fire %>%
  group_by(Date) %>%
  mutate(Total_Acres_Burned = sum(ACRES_BURN)) %>%
  select(Date, Total_Acres_Burned)

r17 <- r17 %>%
  left_join(burnR17) %>%
  replace_na(list(Total_Acres_Burned = 0))
  
```


# Finding an appropriate distribution for the intensity data

I landed on the Power Law Distribution. Prior to learning that this was common knowledge (lol),
I checked the data to see if it fit. Unsurprisingly, it does. Here are those results:


```{r check-power-law-dynamics}

discrete <- ceiling(nonZero_PTA$Total_Acres_Burned) # Values must be discrete, so I rounded up


pl_fit <- displ$new(discrete)
est <- estimate_xmin(pl_fit)
pl_fit$setXmin(est)

alpha <- pl_fit$pars # Between 1.5 and 3.5 - check

cat("If the data fits a power law distribution, the value of the exponent (alpha) is typically between 1.5 - 3.5 for natural phenomena. The alpha value for the PTA East data is:", alpha)


xmin <- pl_fit$xmin # power law begins immediately

```

Using a power law distribution with a hurdle model is a bit trickier than it's worth, so I'm using a lognormal distribution instead. I compared gamma, lognormal, and weibull distributions to see which fit the data best (using PTA as an example). Lognormal it is. 

```{r Distr-for-Hurdle}

fits <- list(
  gamma = fitdistr(nonZero_PTA$Total_Acres_Burned, "gamma"),
  lognormal = fitdistr(nonZero_PTA$Total_Acres_Burned, "lognormal"),
  weibull = fitdistr(nonZero_PTA$Total_Acres_Burned, "weibull"),
  pl_fit
)

sapply(fits, AIC)

```

Here are the Hurdle Model results using the same predictors for each part:

```{r PTA-Hurdle}

hurdle_model <- glmmTMB(
  Total_Acres_Burned ~ Temp + KBDI, # variables affecting fire size
  zi = ~ ., # vars affecting change (i.e., probability of getting a zero)
  family = gaussian(),
  data = ptaE
)

summary(hurdle_model)

```

For shits and giggles, I switched up the variables for the second part (explaining probability of "no fire") to see what would happen. I'm not showing the results, but I ran two models, one with Temp + FM1 as predictors and one with Temp + RnDr (both FM1 and RnDr were original candidates). 

Neither improved the model over Temp + KBDI.


The next thing I did was compare Temp + KBDI to Temp only, In the basic logistic regression analysis, Temp + KBDI was the top model. 

```{r}

hurdle_model_TempOnly <- glmmTMB(
  Total_Acres_Burned ~ Temp, # variables affecting fire size
  zi = ~ ., # vars affecting change (i.e., probability of getting a zero)
  family = gaussian(),
  data = ptaE
)

summary(hurdle_model_TempOnly)


```


```{r compare-temp+KBDI-to-Temp}

models <- list(
  modTemp_KBDI = hurdle_model,
  modTemp = hurdle_model_TempOnly
)

# Create comparison dataframe

model_comparison <- data.frame(
  Model = names(models),
  AIC = sapply(models, AIC),
  AICc = sapply(models, AICc),  # Add AICc
  BIC = sapply(models, BIC),
  LogLik = sapply(models, function(x) logLik(x)[1]),
  DF = sapply(models, function(x) attr(logLik(x), "df"))
)

# Sort by AICc 

model_comparison <- model_comparison[order(model_comparison$AICc),]

# Calculate AICc differences

model_comparison$delta_AICc <- model_comparison$AICc - min(model_comparison$AICc)

# Calculate AIC weights
model_comparison$AIC_weight <- exp(-0.5 * model_comparison$delta_AIC) / 
                              sum(exp(-0.5 * model_comparison$delta_AIC))

knitr::kable(model_comparison,
             caption = "Temp vs. Temp_KBDI for PTA East",
             digits = 2) %>%
    kable_styling(bootstrap_options = c("striped", "hover"),
                full_width = FALSE)

```

Using this framework, Temp alone outcompetes Temp + KBDI for best model for PTA East. The column "AIC_weight" is the probability of that model being the best. (Don't confuse 'AIC weight' with 'variable importance weights'; they are different things) 


## ZERO-INFLATED NEGATIVE BINOMIAL MODEL

**Temp + KBDI for both parts**

```{r ZINB-Temp+KBDI}

zinb_temp_KBDI  <- zeroinfl(
  Count ~ Temp + KBDI |  # Main model
    Temp + KBDI,                      # Zero-inflation model
  data = ptaE,
  dist = "negbin"  # Negative binomial distribution
) 

summary(zinb_model)

```

Interestingly, the results from this model show that KBDI may be 
predictive of # of fires, but isn't a strong predictor of occurrence.

I'm going to try modeling 'Count' using KBDI to predict number of fires and Temp to predict occurrence

```{r ZINB-differentVars}

zinb_diff <- zeroinfl(
  Count ~ KBDI | Temp,
  data = ptaE,
  dist = "negbin"
)

summary(zinb_diff)

```

Huh. That's interesting.


## COMPARE PRESENCE-ABSENCE COMPONENT


I have to extract the presence-absence component from the hurdle and ZINB models in order to compare them fairly to the logistic models


```{r}

# Make sure data is in factor form

ptaE$Presence <- as.factor(ptaE$Presence)


# Model Predictions

logistic_Temp_KBDI_pred <- predict(logistic_Temp_KBDI, 
                                   type = "response")

logistic_Temp_pred <- predict(logistic_Temp, type = "response")
zinb_temp_KBDI_pred <- predict(zinb_temp_KBDI, type = "zero")
zinb_Temp_pred <- predict(zinb_Temp, type = "zero")
hurdle_tempKBDI_pred <- predict(hurdle_tempKBDI, type = "zprob")
hurdle_TempOnly_pred <- predict(hurdle_TempOnly, type = "zprob")

# Adjust Hurdle and ZINB models so that we're looking at the probability of a fire, not a zero

zinb_Temp_pred <- 1 - zinb_Temp_pred
zinb_temp_KBDI_pred <- 1 - zinb_temp_KBDI_pred

hurdle_tempKBDI_pred <- 1 - hurdle_tempKBDI_pred
hurdle_TempOnly_pred <- 1 - hurdle_TempOnly_pred

```


```{r model-comparison-pta}

# Compare AUC's

# Create ROC objects

roc_log_Temp <- roc(ptaE$Presence, logistic_Temp_pred)
roc_log_tempKBDI <- roc(ptaE$Presence, logistic_Temp_KBDI_pred)
roc_hurdle_Temp <- roc(ptaE$Presence, hurdle_TempOnly_pred)
roc_hurdle_tempKBDI <- roc(ptaE$Presence, hurdle_tempKBDI_pred)
roc_zinb_Temp <- roc(ptaE$Presence, zinb_Temp_pred)
roc_zinb_tempKBDI <- roc(ptaE$Presence, zinb_temp_KBDI_pred)


compare_AUCs <- data.frame(
    Model = c("hurdle_Temp", "hurdle_temp_KBDI",
            "logistic_Temp", "logistic_Temp_KBDI",
            "zinb_Temp", "zinb_temp_KBDI"),
  AUC = c(
    auc(roc_hurdle_Temp),
    auc(roc_hurdle_tempKBDI),
    auc(roc_log_Temp),
    auc(roc_log_tempKBDI),
    auc(roc_zinb_Temp),
    auc(roc_zinb_tempKBDI)
  )
)

```

```{r}

print(compare_AUCs)

```

























  
  

  
  
  
  
  
  
  
  
  
  












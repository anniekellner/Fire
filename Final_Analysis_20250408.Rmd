---
title: "Final Analysis"
author: "Annie Kellner"
date: "2025-04-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r load-libraries}

library(tidyverse)
library(kableExtra)
library(pscl) # for zero-inflated model
library(MASS) # for negative binomial distribution
library(MuMIn) # for model comparison

```

```{r load-data, message=FALSE, warning=FALSE}

# Fire data to get intensity metrics

pta_fire <- read_csv("./Data/PTA_East/PTA_East_FDRS_Wildfires.csv")
r17_fire <- read_csv("./Data/Range17/PTA_Off_Post_Fire_History.csv")
kma_fire <- read_csv("C:/Users/akellner/OneDrive - Colostate/Documents/Fire/Data/KMA_Wx_Fire_Data/KMA_FDRS_Wildfires.csv")

# Dataframes with Presence/Absence and Weather Station Data

kma <- readRDS(file = "./Data/CompleteDFs/KMA_20250327.Rds")
ptaE <- readRDS(file = "./Data/CompleteDFs/ptaE_20250327.Rds")
r17 <- readRDS(file = "./Data/CompleteDFs/r17_20250327.Rds")

# Make Presence/Absence columns factor class

kma$Presence <- as.factor(kma$Presence)
ptaE$Presence <- as.factor(ptaE$Presence)
r17$Presence <- as.factor(r17$Presence)

```

```{r dataframe-prep}

# Dates to date object

pta_fire$Date <- as.Date(pta_fire$Date, format = "%m/%d/%Y")
r17_fire$Date <- as.Date(r17_fire$Date, format = "%m/%d/%Y")
kma_fire$Date <- as.Date(kma_fire$Date, format = "%m/%d/%Y")

```

# FIRE INTENSITY

Fire intensity can be measured either by total acres burned or by the number of fires in a given day. I have provided both measurements for all three areas in this dataframe. 

```{r intensity--multiple-fires}

## Fire Intensity - Acres Burned & Multiple Fires
  
# Create DF

intensity <- data.frame(
    matrix(NA, 
           nrow = 7,  # Number of metrics you want to track
           ncol = 3,  # Number of locations
           dimnames = list(
               c("Days_w_Multiple_Fires",
                 "MaxFires_OneDay",
                 "Days_2Fires",
                 "Days_3Fires",
                 "Days_4Fires",
                 "Acres_5+",
                 "Acres_2+"),  # Row names
               c("KMA", "PTA", "Range17")  # Column names
           )
    )
)


## Acres Burned

# KMA

kma5fire <- kma_fire %>%
  filter(acres >= 5)  

intensity["Acres_5+", "KMA"] <- tally(kma5fire)$n

kma2fire <- kma_fire %>%
  filter(acres >= 2) #%>%
  #select(Date, acres) 

intensity["Acres_2+", "KMA"] <- tally(kma2fire)$n

intensity["Days_w_Multiple_Fires", "KMA"] <- 29
intensity["MaxFires_OneDay", "KMA"] <- 3
intensity["Days_2Fires", "KMA"] <- 28
intensity["Days_3Fires", "KMA"] <- 1
intensity["Days_4Fires", "KMA"] <- 0

# PTA East

pta5fire <- pta_fire %>%
  filter(acres >= 5) %>%
  arrange(Date)

intensity["Acres_5+", "PTA"] <- tally(pta5fire)$n

pta2fire <- pta_fire %>%
  filter(acres >= 2) %>%
  arrange(Date)

intensity["Acres_2+", "PTA"]<- tally(pta2fire)$n

intensity["Days_w_Multiple_Fires", "PTA"] <- 26
intensity["MaxFires_OneDay", "PTA"] <- 4
intensity["Days_2Fires", "PTA"] <- 18
intensity["Days_3Fires", "PTA"] <- 7
intensity["Days_4Fires", "PTA"] <- 1

# PTA West/Range 17

r17_5fire <- r17_fire %>%
  filter(ACRES_BURN >= 5) %>%
  arrange(Date)

intensity["Acres_5+", "Range17"] <- tally(r17_5fire)$n

r17_2fire <- r17_fire %>%
  filter(ACRES_BURN >= 2) %>%
  arrange(Date)

intensity["Acres_2+", "Range17"] <- tally(r17_2fire)$n


intensity["Days_w_Multiple_Fires", "Range17"] <- 20
intensity["MaxFires_OneDay", "Range17"] <- 4
intensity["Days_2Fires", "Range17"] <- 15
intensity["Days_3Fires", "Range17"] <- 4
intensity["Days_4Fires", "Range17"] <- 1


# Summary Table

knitr::kable(intensity,
             caption = "Summary of Fire Intensity") %>%
    kable_styling(bootstrap_options = c("striped", "hover"),
                full_width = FALSE) %>%
  row_spec(0:nrow(intensity),
           background = "white",
           color = "black")

```


## THE ZERO-INFLATED NEGATIVE BINOMIAL MODEL (ZINB)

The Hurdle and ZINB models are similar in that both are two-part models that can model fire presence/absence separately from intensity. 

I have decided that the ZINB model is a superior tool for this analysis because it can calculate probabilities associated with both the presence/absence and intensity components of the model (in other words, ZINB can distinguish between days on which fires were impossible vs. days on which fires were probable but did not occur). Hurdle models cannot make this distinction, and therefore cannot provide probabilities associated with fire risk. 

The reason for this difference is the way in which zeros are handled in the model. Essentially, Hurdle models assume that fires could *not* have occurred on days with zeros, whereas the ZINB model allows for the possibility that a fire *could* have occurred, but did not (for example, weather conditions may have been suitable for a fire, but owing to a lack of ignition, no fires occurred). 

The restriction associated with the ZINB is that the data must be discrete, whereas Hurdle models can accommodate both discrete and continuous data. In our case, 'acreage burned' is continuous, and count data (# fires) is discrete. If for some reason it is more desirable to use Acres Burned as a response variable for Intensity, the Hurdle model can be substituted for the ZINB model, but will not provide probabilities associated with fire risk. 

# PTA East

Because I used PTA East as a 'case study' when exploring methods, I already determined that KBDI is the best predictor of Fire Intensity, and Temperature is the best predictor of Presence/Absence. When I used both variables to predict both aspects of the model, KBDI emerged as significant in the 'Count' portion and Temperature emerged as significant in the 'Presence/Absence' portion. Neither was significant in the reverse.  

*Model Summary*

```{r ZINB-ptaE}

ptaE_ZINB <- zeroinfl(
  Count ~ KBDI | Temp, # The variable to the left of the "|" is the predictor of Count (intensity), and the variable to right is the predictor of Presence/Absence
  data = ptaE,
  dist = "negbin" # Negative Binomial distribution 
)

summary(ptaE_ZINB)

```


*How to get Presence/Absence Probability*

```{r ptaE-PA-prob}

# Zero-inflation probabilities

ptaE_zero_probs <- predict(ptaE_ZINB, type = "zero")

head(ptaE_zero_probs)

```


*How to get Count Probability*

```{r ptaE-count-Prob}

# Count probabilities

ptaE_count_probs <- predict(ptaE_ZINB, type = "count")

head(ptaE_count_probs)

```

*AUC values*

```{r AUC-Count}

# Predictions for count data

nonZero_PTA <- ptaE$Count > 0

count_predictions <- predict(ptaE_ZINB, type = "count")[nonZero_PTA]
actual_counts <- ptaE$Count[nonZero_PTA]

# Create ROC for count predictions using a threshold

roc_ZINB_ptaE_count <- roc(
  response = ifelse(actual_counts > median(actual_counts), 1, 0),
  predictor = count_predictions
)

aucCount_ptaE <- auc(roc_ZINB_ptaE_count)

cat("The AUC for the Count portion of the model is", aucCount)


```

```{r AUC-PA}


ZINB_PA_pred_ptaE <- predict(ptaE_ZINB, type = "zero")

roc_ZINB_PA_ptaE <- roc(ptaE$Presence, ZINB_PA_pred_ptaE)

auc_PA_ptaE <- auc(roc_ZINB_PA_ptaE)

cat("The AUC for the Presence/Absence portion of the model is", auc_PA_ptaE)

```



# Range 17 (PTA West)

The logistic regression analysis revealed the following variables to be predictive of fire occurrence in PTA West:
  1. KBDI
  2. BI
  3. RnDr
  
I experimented with various combinations of these variables in each of the two model components (Fire Presence & Fire Intensity). I was not able to run all possible combinations because some models did not converge. Instead, I ran the models in coherent chunks to test whether KBDI would be important for Occurrence, Intensity, or both for PTA West. The reasoning behind this strategy was that KBDI had emerged as predictive of Occurrence in the logistic model for PTA West, but the results from PTA East showed it to be important for Intensity only. 

This first set compares models with KBDI in the 'Intensity' component against models *without* KBDI in the Intensity component.    
On a separate note, I also removed RnDr entirely from one of the models, as that variable came out as less important than the others in the original logistic regression analysis. For the sake of simplicity, I wanted to see whether RnDr would explain enough "variance" to be worth including.  

I've written out the first suite of models I ran below. 
The notation reads as {*Predictors of Intensity* | *Predictors of Occurrence*}.  

  * KBDI + BI + RnDr | KBDI + BI + RnDr (global model)
  
  *remove RnDr*
  
  * KBDI + BI | KBDI + BI + RnDr (remove RnDr from Intensity only)
  * KBDI + BI + RnDr | KBDI (remove RnDr from Occurrence only)
  * KBDI + BI | KBDI + BI (remove RnDr altogether; KBDI + BI on both sides)
  
  * BI | KBDI + BI (BI alone explains Intensity)
  * KBDI + BI | KBDI (KBDI alone explains occurrence)
  
  
  *put RnDr back in*
  
  * KBDI + BI + RnDr | KBDI (KBDI alone explains occurrence)
  
  *remove KBDI from Intensity*
  
  * BI + RnDR | KBDI + BI + RnDr (all three explain occurrence)
  * BI | KBDI + BI + RnDr (BI alone explains Intensity)
  * BI + RnDr | KBDI + BI (RnDr does NOT explain occurrence)
  * BI + RnDr | KBDI (KBDI alone explains occurrence and does NOT explain Intensity)

```{r}

options(na.action = "na.omit") # na.fail is required for dredging, which may explain the lack of convergence


# Model list 

model_list1 <- list(
  "globalModel" = globalModel, 
  
  # Remove RnDr 
  
  "KBDIBI_all" = KBDIBI_all, # remove RnDr from Intensity only
  "NoRnDr" = NoRnDr, # Remove RnDr from both sides
  "BI_KBDIBI" = BI_KBDIBI, # BI alone explains Intensity
  "KBDIBI_KBDI" = KBDIBI_KBDI, # KBDI alone explains Occurrence
  
  # Put RnDr back in model
  
  "all_KBDI" = all_KBDI, # KBDI alone explains Occurence
  
  # Remove KBDI from Intensity
  
  "BIRnDr_all" = BIRnDr_all, # All three explain occurrence
  "BI_all" = BI_all, # BI alone explains Intensity
  "BIRnDr_KBDIBI" = BIRnDr_KBDIBI, # RnDr does NOT explain Occurrence
  "BIRnDr_KBDI" = BIRnDr_KBDI # KBDI alone explains occurrence but does NOT explain Intensity
)

aicc_values <- sapply(model_list1, function(x) {
  AICc(x)
})

# Create comparison table

model_comparison1 <- data.frame(
  Model = names(model_list1),
  AICc = aicc_values,
  Delta_AICc = aicc_values - min(aicc_values)
)

# Sort by AICc

model_comparison1 <- model_comparison[order(model_comparison$AICc),]

# Print results

knitr::kable(model_comparison1,
             caption = "AICc jump when KBDI is removed from Intensity",
             digits = 2) %>%
    kable_styling(bootstrap_options = c("striped", "hover"),
                full_width = FALSE)

```

Important takeaways from this first run:
  1. KBDI is essential to include in the Intensity component (note the jump in Delta AICc when it's removed)
  2. RnDr must be included
  3. KBDI alone is not sufficient to predict Occurrence
  

For PTA East, I was able to hone in on the best model by examining the coefficients (and their significance) in the global model (it was easier because there were only two significant variables). 

If I did the same for PTA West, that model would be KBDI + BI + RnDr | KBDI + BI. Let's see if that combination outcompetes the global model. 
  
```{r}

all_KBDIBI <- zeroinfl(
  Count ~ KBDI + BI + RnDr | KBDI + BI,
  data = r17,
  dist = "negbin"
)

summary(all_KBDIBI)

model_list2 <- list(all_KBDIBI, globalModel)

# Calculate AICc for each model

aicc_values <- sapply(model_list2, function(x) {
  AICc(x)
})

aicc_values

```
  
Well look at that. It worked. I think it's pretty safe to say the best model is {KBDI + BI + RnDr | KBDI + BI}

I can try to play around with the Occurrence, and/or do an AUC analysis if it's of interest. 

Here are the coefficients:

```{r best-model-Range17} 

summary(all_KBDIBI)

```  

I will make you a table for each location with the Dates, explanatory variables, Presence, Count, Acres Burned, and Fire Probability. 


##  KMA

Running all possible combinations of the two candidate variables, F100 and FM1.

```{r}




```




Global Model is F100 + FM1 | F100 + FM1

```{r}


options(na.action = "na.omit")



globalModel <- zeroinfl(
  Count ~ F100 + FM1 | F100 + FM1,
  data = kma,
  dist = "negbin"
)

F100 <- zeroinfl(
  Count ~ F100 | F100,
  data = kma, dist = "negbin"
)

F100_FM1 <- zeroinfl(
  Count ~ F100 | FM1,
  data = kma,
  dist = "negbin"
)

F100_F100FM1 <- zeroinfl(
  Count ~ F100 | F100 + FM1,
  data = kma,
  dist = "negbin"
)

F100FM1_F100 <- zeroinfl(
  Count ~ F100 + FM1 | F100,
  data = kma,
  dist = "negbin"
)

F100FM1_FM1 <- zeroinfl(
  Count ~ F100 + FM1 | FM1,
  data = kma,
  dist = "negbin"
)

FM1 <- zeroinfl(
  Count ~ FM1 | FM1,
  data = kma,
  dist = "negbin"
)

FM1_F100 <- zeroinfl(
  Count ~ FM1 | F100, 
  data = kma, 
  dist = "negbin"
)

FM1_F100FM1 <- zeroinfl(
  Count ~ FM1 | F100 + FM1,
  data = kma,
  dist = "negbin"
)

model_list_KMA <- list(
  "globalModel" = globalModel,
  "F100" = F100,
  "F100_FM1" = F100_FM1,
  "F100_F100FM1" = F100_F100FM1,
  "F100FM1_FM1" = F100FM1_FM1,
  "F100FM1_F100" = F100FM1_F100,
  "FM1_F100FM1" = FM1_F100FM1,
  "FM1_F100" = FM1_F100,
  "FM1" = FM1)


# Compare using AICc

model_comparison_kma <- data.frame(
  Model = names(model_list_KMA),
  AICc = aicc_values,
  Delta_AICc = aicc_values - min(aicc_values)
)

model_comparison_kma <- model_comparison_kma[order(model_comparison_kma$AICc),]

# Print results

knitr::kable(model_comparison_kma,
             caption = "AICc jump when KBDI is removed from Intensity",
             digits = 2) %>%
    kable_styling(bootstrap_options = c("striped", "hover"),
                full_width = FALSE)
```
The top model for KMA is F100 + FM1 | FM1

In all the top models (AICc <2), FM1 is the best predictor of Occurrence. If you need to use linear regression, using FM1 only will suffice for fire presence/absence. 

```{r DF-with-mu-pi-probs}

ptaE$mu <- 

```



















